{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライン情報と選手の脚質を取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得元: WinTicket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racecard_url = \"https://www.winticket.jp/keirin/keiokaku/racecard/2021010127/2/3\"\n",
    "# raceresult_url = \"https://www.winticket.jp/keirin/yokkaichi/raceresult/2022010448/3/8\"\n",
    "# req = requests.get(raceresult_url)\n",
    "# soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日程を与えるとその日開催されたレースのURLをリストで返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(year, month, day):\n",
    "    url = \"https://www.winticket.jp/keirin/racecard/\" + str(year) + str(month).zfill(2) + str(day).zfill(2)\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    url_soup = soup.find_all('a', rel='nofollow')\n",
    "    urls = [i.get('href') for i in url_soup]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### urlを与えると脚質のデータフレームを返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_legtype_table(url):\n",
    "    race_tables = pd.read_html(url)\n",
    "    legtype_table = race_tables[1][['車', '脚']].rename(columns={'車':'no', '脚':'leg'}).droplevel(1, axis=1)\n",
    "    return legtype_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### htmlを与えるとライン情報のデータフレームを返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_table(html, number_of_people):\n",
    "    line_soup = html.find_all(\"div\", class_=\"sc-1y958x7-0\")\n",
    "    line_text = [i.text for i in line_soup][0]\n",
    "    if '競' in line_text:\n",
    "        return None\n",
    "    lines = line_text.split('区切り')\n",
    "\n",
    "    line_data = [[0 for j in range(number_of_people)] for i in range(3)]\n",
    "    for n, i in enumerate(lines):\n",
    "        people = len(i)\n",
    "        for k, j in enumerate(i):\n",
    "            index = int(j) - 1\n",
    "            line_data[0][index] = people\n",
    "            line_data[1][index] = n\n",
    "            line_data[2][index] = k\n",
    "    line_data.insert(0, [i+1 for i in range(number_of_people)])\n",
    "    df = pd.DataFrame({'no':line_data[0],\n",
    "                       'people':line_data[1],\n",
    "                       'group':line_data[2],\n",
    "                       'number':line_data[3]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlを与えると着順のデータフレームを返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_table(url):\n",
    "    result_tables = pd.read_html(url)\n",
    "    result_table = result_tables[0][['着','車']].rename(columns={'着':'no', '車':'result'})\n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここからメイン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. レース情報が乗っているページのURLを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "race_urls = []\n",
    "for year in range(2021, 2022):\n",
    "    for month in range(1, 2):\n",
    "        for day in tqdm(range(1, 2)):\n",
    "            race_urls.extend(get_urls(year, month, day))\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. URLにアクセスして各種データを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [04:59<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "race_data_7 = pd.DataFrame()\n",
    "race_data_9 = pd.DataFrame()\n",
    "\n",
    "for url in tqdm(race_urls):\n",
    "    #レースIDの設定\n",
    "    split_url = url.split('/')\n",
    "    race_id = split_url[4] + \"/\" + split_url[5] + \"/\" + split_url[6]\n",
    "\n",
    "    if (race_id in race_data_7.index) or (race_id in race_data_9.index):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        racecard_url = \"https://www.winticket.jp\" + url\n",
    "        legtype_table = create_legtype_table(racecard_url)\n",
    "        if legtype_table.empty or ('欠' in legtype_table['no']):\n",
    "            continue\n",
    "        time.sleep(1)\n",
    "\n",
    "        number_of_people = len(legtype_table)\n",
    "\n",
    "        req = requests.get(racecard_url)\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "        line_table = create_line_table(soup, number_of_people)\n",
    "        time.sleep(1)\n",
    "\n",
    "        raceresult_url = racecard_url.replace(\"racecard\", \"raceresult\")\n",
    "        result_table = create_result_table(raceresult_url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        #dfの作成，結合\n",
    "        df = pd.concat([legtype_table, line_table, result_table], axis=1)\n",
    "        df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "        df.index = [race_id for i in range(len(df))]\n",
    "\n",
    "        if number_of_people == 7:\n",
    "            race_data_7 = pd.concat([race_data_7, df])\n",
    "        elif number_of_people == 9:\n",
    "            race_data_9 = pd.concat([race_data_9, df])\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        print(url)\n",
    "        print(traceback.format_exc())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7 = race_data_7\n",
    "data_9 = race_data_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>people</th>\n",
       "      <th>group</th>\n",
       "      <th>number</th>\n",
       "      <th>両</th>\n",
       "      <th>追</th>\n",
       "      <th>逃</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020123045/3/3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020123045/3/3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020123045/3/3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020123045/3/3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020123045/3/3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021010181/1/9</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021010181/1/9</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021010181/1/9</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021010181/1/9</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021010181/1/9</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                no  people  group  number  両  追  逃\n",
       "2020123045/3/3   1       1      1       0  0  1  0\n",
       "2020123045/3/3   2       2      0       0  0  1  0\n",
       "2020123045/3/3   3       2      2       1  0  1  0\n",
       "2020123045/3/3   4       2      3       1  0  1  0\n",
       "2020123045/3/3   5       2      2       0  1  0  0\n",
       "...             ..     ...    ...     ... .. .. ..\n",
       "2021010181/1/9   3       2      1       1  0  1  0\n",
       "2021010181/1/9   4       2      1       0  0  0  1\n",
       "2021010181/1/9   5       2      0       0  0  0  1\n",
       "2021010181/1/9   6       2      2       0  0  0  1\n",
       "2021010181/1/9   7       2      2       1  0  1  0\n",
       "\n",
       "[532 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leg_data = pd.get_dummies(data_7['leg'], columns=['逃', '両', '追'])\n",
    "data_7 = pd.concat([data_7, leg_data], axis=1).drop('leg', axis=1)\n",
    "data_7_result = data_7['result']\n",
    "data_7 = data_7.drop('result', axis=1)\n",
    "data_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7[['両', '追', '逃']] = data_7[['両', '追', '逃']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=7)\n",
    "pred = model.fit_predict(data_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ea3eeac9e68bc0e3f703f37c7e2955c9932483a506e1740cfbadba66422ad64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('keirin_prediction': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
